# Hi there, I'm Asad Ali! üëã

[![DataCamp Data Engineer Certification](datacamp_banner.png)](https://www.datacamp.com/certificate/DE0015440477781)

## üöÄ About Me

<div style="display: flex; justify-content: center; align-items: flex-start; gap: 20px; flex-wrap: wrap;">
  <img 
    src="https://github-readme-stats.vercel.app/api/top-langs/?username=asadali27232&layout=compact&card_width=400&langs_count=6&hide=CSS,HTML,JavaScript,Jupyter%20Notebook,HCL,Kotlin,C%23,EJS,C&title_color=ffffff&hide_border=true&theme=github_dark" 
    width="400" 
    style="display: block;"
  />
  <img 
    src="https://github-readme-stats.vercel.app/api/wakatime?username=asadali27232&layout=compact&card_width=400&title_color=ffffff&hide_border=true&theme=github_dark" 
    width="400" 
    style="display: block;"
  />
</div>

I am an **Associate Data Engineer** with hands-on experience building and optimizing ETL pipelines, managing multi-source data ingestion, and working with cloud-based data warehouses including **Snowflake**, **BigQuery**, and **AWS Redshift**.

Skilled in **Python**, **SQL**, **dbt**, and modern data engineering tools such as **Apache Airflow**, **Spark**, and **AWS Glue**, I have expertise in data modeling, pipeline orchestration, and ensuring data quality, reliability, and scalability. I am experienced in transforming raw data into high-quality, analytics-ready datasets, developing data-driven solutions, and contributing to large-scale projects with hundreds of tables and multi-channel pipelines.

---

## üíº Roles & Education

### **Associate Data Engineer**

**Devsinc | Lahore** _(Dec 2025 ‚Äì Present)_

-   Working on a large data project in **Snowflake**, managing data from multiple ingestion channels, and supporting ETL scheduling, monitoring, and reliability for production pipelines.
-   Managing historical data pipelines from **BigQuery**, operating ETLs deployed on **AWS MWAA**, and building scalable **dbt** transformations to standardize models, improve lineage, and ensure high-quality, trusted data for analytics.

### **Associate Python Developer**

**Machine Learning 1 Pvt. Ltd | Lahore** _(Mar 2025 ‚Äì Nov 2025)_

-   Managed a large Python-based validation microservice for a global KYC product, ingesting outputs from multiple **ML models** to perform data validation, standardization, and quality controls across a high volume of traffic.
-   Implemented rule-driven checks, including regex fallbacks, anomaly detection, and checks preventing hallucinations and issues due to cropped artifacts, improving accuracy, reducing bad responses, and strengthening compliance in production.

### **Associate Data Engineer**

**World Wide Admissions Hub | Lahore** _(Aug 2024 ‚Äì Feb 2025)_

-   Developed web scraping scripts, streamlining raw data collection from multiple sources, and increasing data extraction efficiency from 1 website per day to 100 websites per day, resulting in a **100% improvement**.
-   Designed and implemented an **AI-based ETL pipeline** using Python, transforming, cleaning, and ingesting data, thereby enhancing processing efficiency and ensuring consistent, high-quality data for the web app and AI model.

---

## ‚ú® Skills

### **Core Data Engineering**

-   **Programming**: Python, SQL
-   **Frameworks & Tools**: Apache Airflow, Apache Spark, dbt, Apache Kafka, PySpark, Pandas
-   **Cloud Components**: AWS (Glue, Lambda, Redshift, S3, Athena, MWAA), BigQuery, Snowflake, Databricks
-   **Infrastructure**: Docker, Terraform

### **Databases**

-   **Relational**: PostgreSQL, MySQL, MSSQL
-   **NoSQL**: MongoDB

### **Soft Skills**

-   Problem-Solving, Team Collaboration, Continuous Learning

---

## üíª Projects

### [Simple Cloud-Based Data Pipeline with Apache Airflow on AWS EC2](https://github.com/asadali27232/) _(Dec 2025)_

This project implements an end-to-end data engineering pipeline using **Apache Airflow** deployed on an **AWS EC2** Ubuntu instance. The pipeline orchestrates the extraction, transformation, and loading (ETL) of NYC 311 Service Request data through a series of automated tasks. Raw JSON data is fetched from the NYC Open Data API, processed using **Pandas** for data cleaning and standardization, and ultimately stored in **Amazon S3** in Parquet format for optimized query performance.

### [Terraform-Powered AWS Glue ETL: Infrastructure as Code](https://github.com/asadali27232/) _(Dec 2025)_

ETL pipeline using **Terraform** to automate AWS infrastructure provisioning for **Glue**, **RDS**, **S3**, and **Athena**. The system extracts MySQL retail data, transforms it into a star schema via **PySpark** jobs, and loads Parquet-optimized files into S3 for serverless analytics, demonstrating Infrastructure as Code, dimensional modeling, and cost-efficient cloud data engineering.

### [YouTube's Data Engineering: ETL & Cloud Pipeline](https://github.com/asadali27232/) _(Dec 2025)_

This project demonstrates a data engineering pipeline implementation, including ingestion, ETL, and cloud-based storage using **AWS**. It processes structured and semi-structured data to create a clean dataset and builds an interactive **Power BI** dashboard for visualization. The system is scalable, automated, and cloud-based, showcasing real-world data engineering practices.

### [CardioGraph Pro - FYP](https://github.com/asadali27232/FYP) _(Feb 2024 ‚Äì Jan 2025)_

Led the handling and analysis of 20,000 ECG signal files (time-series data) using Python, performing EDA with Pandas and Matplotlib, basic data cleaning, and designing a data pipeline to integrate with a machine learning model and web interface, ensuring efficient and accurate data processing.

---

## üèÜ Certifications

-   [**Certified Data Engineer** - DataCamp](https://www.datacamp.com/certificate/DE0015440477781)
-   [**Snowflake Data Engineering** - Snowflake](https://learn.snowflake.com/en/certifications/snowpro-advanced-dataengineer/)
-   [**Databricks for Data Engineering** - Databricks](https://www.databricks.com/learn/certification/data-engineer-associate)
-   [**dbt Fundamentals** - dbt Labs](https://www.getdbt.com/dbt-learn/)
-   [**Introduction to Data Engineering** - DeepLearning.AI](https://www.coursera.org/learn/introduction-to-data-engineering)
-   [**Programming in Python** - Meta](https://www.coursera.org/learn/programming-in-python-meta)
-   [**Querying Databases with SQL** - IBM](https://www.coursera.org/learn/sql-practical-introduction-for-querying-databases)

---

## üéì Education

**BS Computer Science** | COMSATS University Islamabad, Lahore Campus _(Feb 2021 ‚Äì Jan 2025)_
Developed a strong foundation in programming and computer science principles, with specialized knowledge in data engineering, data warehousing, and database technologies.

---

## üì´ How to Reach Me

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/asadali27232/)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:asadali27232@gmail.com)
[![WhatsApp](https://img.shields.io/badge/WhatsApp-25D366?style=for-the-badge&logo=whatsapp&logoColor=white)](https://wa.me/923074315952)
[![Personal Website](https://img.shields.io/badge/Personal%20Website-24292e?style=for-the-badge&logo=react&logoColor=white&color=purplr)](https://asadali27232.github.io/asadali27232/)
